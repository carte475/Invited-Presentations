---
title: "Structural Equation Modeling in Criminal Justice Research"
author: "Travis M. Carter"
date: "11/29/2021"
output:
  beamer_presentation:
    theme: "Antibes"
    colortheme: "crane"
    fonttheme: "serif"
    number_sections: FALSE 
    slide_level: 2
    keep_tex: TRUE
header-includes:
    - \author{Travis M. Carter}
    - \institute[]{Michigan State University}
    - \usepackage{ragged2e}
    - \renewcommand{\footnotesize}{\tiny}

---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
  library(lavaan)
  library(semPlot)
  library(summarytools)
  library(dplyr)
  library(tidyverse)
  library(mice)
  library(mitools)
  library(semTools)
  library(psych)
  library(GPArotation)
  library(knitr)

load("C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/3CITY_DATA_CLEANED.Rda")

  FOV_DATAFRAME <- data.frame(DTA$FV1, DTA$FV2, DTA$FV3)
  ROV_DATAFRAME <- data.frame(DTA$PR1, DTA$PR2, DTA$PR3)
  FOC_AND_ROV <- data.frame(DTA$FV1, DTA$FV2, DTA$FV3, DTA$PR1, DTA$PR2, DTA$PR3)

```

# What is Structural Equation Modeling (SEM)?

## The basics

- SEM is an advanced statistical method used for testing relationships between *observed* and/or *latent* variables.     
  - *Observed variables*: Directly measurable things (e.g., age, height, years in school)   
  - *Latent variables*: Theoretical constructs  measured indirectly via observed variables (e.g., low self-control, anxiety, social capital)   
  
# Types of SEM techniques   
## Path Analysis   
  - Path analysis (PA) is essentially univariate and multivariate regression analysis wiht only observed variables.   
  ![Path Model Example.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/PATHMOD_PIC.png)

***

## Exploratory and Confirmatory Factor Analysis 
  - Exploratory Factor Analysis (EFA) is a way to identify the number of potential *latent variables* (constructs) that are manifested through a set of *observed variables*. 
  - Check out this link to learn more about the nuts and bolts of EFA.^[https://scholar.google.com/scholar?hl=en&as_sdt=0%2C14&q=A+Beginner%E2%80%99s+Guide+to+Factor+Analysis%3A++Focusing+on+Exploratory+Factor+Analysis+&btnG=]
  - Check this link out to learn about what are the best practices for conducting EFA in your research.^[https://scholar.google.com/scholar?hl=en&as_sdt=0%2C14&q=Best+practices+in+exploratory+factor+analysis%3A+four+recommendations+for+getting+the+most+from+your+analysis+recommendations+for+getting+the+most+from+your+analysis&btnG=] in your research.    
  
  ***
  - Confirmatory Factor Analysis (CFA) takes what we know from EFA and **tests** whether these theoretical constructs are indeed manifestations (in the aggregate) of these observed variables.    
  - We do this by estimating relationships between observed measures that we think might collectively reflect some theoretical construct.    
  ![CFA Example.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/CFA_PIC.png)

## Structural Regression Models   
  - Structural Regression Models (SRM) take what we know about CFA and extends it by allowing us to model the magnitude and direction of relationships between latent variables.   
  - Anything you would do in a multivariate regression environment, you can do in SRM as well--including mediation and moderation!    
  ![SRM Example.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/SRM_PIC.png)


## Latent Change Analysis
  - Latent Change Analysis (LCA) is a longitudinal extentions of CFA.   
  - We can use it to determine if latent constructs change over time within and between respondents (think growth modeling with IQ). 
    - Do folks change in IQ over time within themselves?   
    - Do folks differ in growth rates of IQ between each other?

# Why is SEM important?   
- Recall the general OLS regression equation we all know and love:   
$$
Y = \mu_1 + X_1\beta_1 + ... X_k\beta_k + \epsilon
$$
- Here, $\mu$ is a constant, $X$ is an observed (independent) variable, $Y$ is our outcome variable, and $\epsilon$ is our error term. 

- According to OLS assumptions, $X$ is to be measured perfectly. If not,  $\beta$ will be inconsistent to the extent that $X$ is unreliable.^[Raykov, T., & Marcoulides, G. A. (2006). *A first course in structural equation modeling*. Routledge.]    

***

  - Let's say X is an index scale based on 3 survey items, all of which tap into different elements low self-control.    
  - Each item, however, has some variance that is unshared by all other items.    
  - Multiply this by 3 and you have three times the amount of unshared variance that is captured in X but is entirely irrelevant for understanding the true form and function of low self-control. 
  
***

  ![Measurement Error Diagram.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/VENN_ME_PIC.png)   
  
***

- SEM resolves this issue by allowing us to take into account **measurement error** in our theoretical variables of interest.^[Raykov, T., & Marcoulides, G. A. (2006). *A first course in structural equation modeling*. Routledge.]

# How does SEM work?   
  - SEM is based on a system of equations, not a single equation like we see in regular OLS regression models.    
  - We determine whether a latent variable exists by regressing our observed indicators on that latent construct.    
  - We then evaluate fit indices to confirm it exists based on the data at our disposal.   

***   

  - Remember that CFA from earlier? Here is what a model definition of equations might look like for a latent variable with 3 observed variables.    
    
$$
Item_1 = \mu_1 + \lambda_1LSC + \epsilon_1    
$$
$$
Item_2 = \mu_2 + \lambda_2LSC + \epsilon_2  
$$
$$
Item_3 = \mu_3 + \lambda_3LSC + \epsilon_3
$$
- Where $\mu$ is our constant, $\lambda$ is our factor loading, $LSC_1$ is our latent variable, and our outcome is each observed variable tapping into low self-control.   
- We have rules for determining which parameters are estimated in these equations for those interested in learning the nuts and bolts, **which I highly recommend** (See Supplementary materials at the back of my presentation).

# How do we use SEM in CJ research: An example      
  -	Say we have a sample of survey responses from a large victimization survey.    
  -	We are interested in understanding whether people's perceived risk of being victimized drives their concern for personal safety.     
  -	Here's a snapshot of our survey items.    

***

  ![Survey Items.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/FOC_ITEMS_PIC.png)   

***

  ![Survey Items.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/ROV_ITEMS_PIC.png)   

***
## EFA   

  - First, let's say we were interested in determining whether these items hang together, or if they tap into different constructs.   
    - Let's run an EFA on all six of our survey items. 

***

## EFA R output: Factor Loadings

```{r EFA_LOADINGS, echo = TRUE}
TABH <- psych::fa(FOC_AND_ROV, 
                  nfactors = 2, 
                  rotate = "oblimin")
```

```{r EFA_LOADINGSOUTPUT, echo = FALSE}
kable(head(TABH$loadings), 
            col.names = c("1-Factor Model", "2-Factor Model"),
            caption = "EFA Results: Oblique Rotated Factor Loadings")
```

***
## EFA R output: Eigenvalues
```{r EFA_EIGENVALUES, echo=TRUE}
TABH <- psych::fa(FOC_AND_ROV, nfactors = 2, 
                  rotate = "oblimin")
```
```{r EFA_EIGENVALS_TABLE, echo = FALSE}
knitr::kable(TABH$Vaccounted, digits = 2, 
             col.names = c("1-Factor Model", "2-Factor Model"),
             caption = "EFA Results: Eigenvalues and Variances")
```

***
## CFA  

  - OK, looks like they fall into diff constructs based on rotated factor loadings... what if we want to confirm whether the data fits this well? Enter in CFA.   

***

## CFA R output: Create the model   

- The first step in developing our CFA is to write out our model definition of equations.   

```{r CFA_EQUATION, echo=TRUE}
  attach(DTA)
  MEASUREMENT_MODEL <- '
  # LATENT VARIABLE DEFINITION OF EQS
    FEAR      =~ FV1 + FV2 + FV3
    RISK      =~ PR1 + PR2 + PR3
  '

```

***
## CFA R output: Estimate the model   

```{r CFA_MEASMODELEST, echo=TRUE}
  fit_MM <- cfa(MEASUREMENT_MODEL, 
                data = DTA,
                ordered = T)

```
## CFA R output: How to evaluate fit of model   

- According to Raykov and Marcoulides (2006) A good fitting model has the following.^[Raykov, T., & Marcoulides, G. A. (2006). *A first course in structural equation modeling*. Routledge.]   
  - An RMSEA value $< = .05$   
  - Alternative for RMSEA: The lower bound of the 90% confidence interval is $< = .05$ and its upper bound is $< = .08$.   
  - CFI and TLI are $> = .95$ ($> = .90$ for acceptable fit)   
  - A non-significant $\chi^2$ value (this is biased towards the null in large samples).     
  - No negative residual variances in our model (more on this later).
  
***

## CFA R output: Now let's evaluate the fit of our model   
  
```{r CFA_MODELFIT, echo = TRUE}
  FIT_INDICES_MM <- fitMeasures(fit_MM, 
                                c("chi" , "rmsea",
                                  "rmsea.ci.upper",
                                  "rmsea.ci.lower", 
                                  "tli","cfi"))
```
```{r CFA_MODELFITOUTPUT, echo=FALSE}
  FIT_INDICES_MM <- round(FIT_INDICES_MM, digits = 3)
  kable(FIT_INDICES_MM, 
        caption = "Fit Indices for Measurement Model",
        col.names = c("Fit Stats"))
```

## CFA R output: Make a plot of our results
```{r CFA_MODELPLOT, echo = TRUE}
semPaths(fit_MM, residuals = T, 
         "std", fade = FALSE, posCol = c("black"), 
         color = c("yellow"), 
         edge.label.cex = 1.25, edge.label.font = 1.25)
```

## SRM   
- Ok, looks like we are dealing with 2 different constructs... potentially. Without getting into the weeds, let's see if risk has any predictive influence on fear.   

***
- Here is the input for our model:

```{r SRM_INPUT, echo = TRUE}
  STRUCTURAL_MODEL <- '
  # LATENT VARIABLE DEFINITION OF EQS
    FEAR      =~ FV1 + FV2 + FV3
    RISK      =~ PR1 + PR2 + PR3

  # STRUCTURAL REGRESSION MODEL
    FEAR       ~ RISK
  '
  fit_SM <- sem(STRUCTURAL_MODEL, 
             data = DTA, 
             ordered = T)
```

***

Here is the fit of our model. 
Do we like what we see?
```{r SRM_FIT, echo=FALSE}
  FIT_INDICES_SM <- fitMeasures(fit_SM, 
                                c("chi" , "rmsea",
                                  "rmsea.ci.upper",
                                  "rmsea.ci.lower", 
                                  "tli","cfi"))
  FIT_INDICES_SM <- round(FIT_INDICES_SM, digits = 3)
  kable(FIT_INDICES_SM, 
        caption = "Fit Indices for Structural Model",
        col.names = c("Fit Stats"))
```

***

Here is a figure for our model.    

```{r SRM_MODELPLOT, echo = FALSE}
semPaths(fit_SM, residuals = F, style = "mx", 
         "std", fade = FALSE, posCol = c("black"), 
         color = c("yellow"), 
         edge.label.cex = 1.25, edge.label.font = 1.25)
```

***
Here is the output for our SRM. 
```{r SRM_MODELGATHEREST, echo=TRUE, include=FALSE}
SRM_FIT_OUTPUT <- summary(fit_SM)
```

```{r SRM_MODELOUTPUT, echo=FALSE}
kable(head(SRM_FIT_OUTPUT$PE, n = 7), digits = 2,
      col.names = c("LHS", "OPERATOR", "RHS", "EXO", 
                    "Est.", "S.E.", "Z Stat.", "p"), 
      caption = "Structural Model Results")
```

# SEM in CJ wrap-up   
- What is SEM?   
- Why do we use SEM?   
- What applications does SEM have in our research?   
- What if you want to learn more?   
  - Books:   
    - Raykov, T., & Marcoulides, G. A. (2012). *A first course in structural equation modeling*. Routledge.     
    - Kline, R. B. (2015). *Principles and practice of structural equation modeling*. Guilford publications.   
  - Websites:   
    - Lavaan resource page **https://lavaan.ugent.be/**   
    - UCLA IDRE resource page **https://stats.idre.ucla.edu/r/seminars/rsem/**    

***

  - Articles:   
    - Jacinta Gau has a great best practices article   
      - Gau, J. M. (2010). Basic principles and practices of structural equation modeling in criminal justice and criminology research. *Journal of Criminal Justice Education*, 21(2), 136-151.   
    - *Lavaan* Package article   
      - Rosseel, Y. (2012). Lavaan: An R package for structural equation modeling and more. Version 0.5-12 (BETA). *Journal of Statistical Software*, 48(2), 1-36.   
  - Researchers:   
    - Dr. Joe Hamm    
    - Dr. George Burruss   
    - Dr. Johnathan Jackson   
  - Courses @ MSU:   
    - **CEP 938** *Latent Variable Modeling* by Dr. Tenko Raykov   
    - **SOC 883** *Multi-Equation Quantitative Models* by Dr. Sandra Marquart-Pyatt   
    - **HDFS 961** *Applied Structural Equation Modeling* by Dr. Amy Nuttall     
    - **HDFS 962** *Longitudinal Structural Equation Modeling* by Dr. Amy Nuttall   
    
# ICPSR   
- One alternative to taking a course here at MSU is to take one through the ICPSR summer program.   
  - https://www.icpsr.umich.edu/web/pages/sumprog/  
- They host tons of courses ranging in methodological and quantitative topics   
  - Regression Analysis 1-3     
  - Generalized Linear Models 1-2       
  - Measurement, scaling, etc.    
  - Time Series Analysis 1-2   
  - Multilevel Modeling 1-2   
  - Bayesian Stats    
  - Network Analysis   
- Great use of your summer fellowship!   
  
# Thanks for listening!     
- You can find me on these platforms   
  - **Twitter**: https://twitter.com/tcarter_MSU 
  - **GitHub**: https://github.com/carte475    
  - **SCJ Directory**: https://cj.msu.edu/directory/carter-travis.html   
- If you have any further questions or want to meet up and nerd-out about stats, here is my email: carte475@msu.edu    

# Supplemental materials
## How do we identify a model in SEM?   

- In OLS regression, we generally need not worry about identifying a model (specifying which parameters to be estimated) apart from our exogenous (independent) and endogenous (dependent) variables.    
- In SEM, we must carefully consider what is and is not to be estimated.   
- Remember our CFA model with 3 observed variables and 1 latent variable? Here it is again as written out in the form of equations. 
  
$$
Item_1 = \mu_1 + \lambda_1LSC + \epsilon_1    
$$
$$
Item_2 = \mu_2 + \lambda_2LSC + \epsilon_2  
$$
$$
Item_3 = \mu_3 + \lambda_3LSC + \epsilon_3
$$

***

- Remember, $\mu$ is our constant, $\lambda$ is our factor loading, $LSC_1$ is our latent variable, and our outcome is each observed variable tapping into low self-control.    

***

- In this structural equation model, we have 3 equations as opposed to one equation to worry about.   
  - How? We have three outcome variables based on the three survey items tapping into low self-control.   
  - **Note**: In SEM, our observed variables tapping into the latent variable are considered endogenous. 
- Based on this information, we need to determine which relationships between observed and unobserved variables will be estimated via the parameters in our model and which and which will not be estimated.
  - Why not estimate them all? We have only so many observed variables to then determine potential relationships with latent variables! They are a finite resource!       
  
- **QUESTION**: How many exogenous and endogenous variables are in the model above?   

***

- **ANSWER**: 
  - We have 6 exogenous variables (3 error terms + 3 latent variable factor loadings = 6).   
  - We have 3 endogenous variables (3 observed items) and 3 constants.       

- Fun fact: In SEM, our constants ($\mu$) are the observed item means across our entire sample.    
  - If $Item_1$ measured respondent aggressiveness and the mean score across our sample for that variable was (out of 10) $\bar{x} = 3.5$, then $\mu_1 = 3.5$. 
  
- Fun fact 2: In SEM, our residuals are independent variables.    
  - A residual captures the amount of variation in an observed variable that is due to measurement error.    
  - In other words, a residual is the amount of item variance *unshared* with all other measures of a common factor (i.e., LSC)

***   

- Now let's figure out how to identify a model based on Raykov and Marcoulides (2006) 6 rules for determining model parameters.     

1. All variances of our exog. variables are model parameters.   
2. All covariances between exog. variables are model parameters.    
3. All factor loadings ($\lambda$) are model parameters.    
4. All regression coeffs are model parameters.    
5. The variances and covariances between and of our endog. variables (and between our exog. and endog. variables) are not model parameters.   
  5.1 Why? B/c these variances and covariances are explained by model parameters already.   
6. For each latent variable, we must set it's scale to identify a model.   
  6.1 We can do this by "fixing" one of it's factor loadings to a constant such as 1, or we can set it's variance to 1.    
  
***   

Based on what we now know, let's go about determining the number of estimable parameters in our model. Given our rules... how many do we need to estimate?       

 ![CFA Example.](C:/Users/travi/OneDrive - Michigan State University/Brakebills 1st Year/Academic Progress/Invited Presentations/CFA_PIC.png)


***   

Let's go through the rules.     

- Rule 1 says we should estimate 4 parameters.   
- Rule 2 says we should estimate 0 parameters.         
  - Why? It is assumed our residuals are uncorrelated! Also, we have only one latent variable, if there were 2 or more, then we would estimate covariance parameters.   
- Rule 3 says we should estimate 3 parameters.   
- Rule 4 says we should estimate 0 parameters.          
  - Why? No regression coeffs. This is a CFA, not a PA or SRM.    
- Rule 5 is acknowledged.      
- Rule 6 says we should subtract 1 parameter from the total number of estimable parameters.      
  - We can do this by fixing the variance of Social Disorganization or by fixing one of it's three factor loadings to $\lambda = 1$.    

This gives us a total of 6 "free" parameters to be freely estimated.

***

## How do we estimate model parameters in SEM?   

- Without getting into the nitty-gritty details, parameter estimation in SEM can be **roughly** defined through the following steps.   

1. Identify your model by determining which parameters are free (estimable) and which are not.  We just did this! 
2. Create a matrix of the covariance relationships between your model parameters to be estimated.   
3. Rinse and repeat a process of defining the values for those relationships based on how well they fit the observed data at your disposal.    
  3.1 The process of estimation is usually done through Maximum Likelihood expectation, which explains the iterative estimation process described above.   
  
***   

4. Upon finding a model that minimizes the "distance" between our observed matrix of data and the specified matrix of relationships between parameters, we then use goodness-of-fit (GOF) indices to determine which values and models fit best to our data.   

***   

## A note on estimating SEM parameters.   

We mentioned one cannot estimate all parameters in a model because we have so many degrees of freedom to give.   

Here is a further note on what that really means.    

- In our CFA model example, we have 3-observed variables and  1-latent variable.    
- Based on this information, we have approximately 3 non-redundant elements (observed variables) $p = 3$.   
- The reason we care about non-redundant elements is that we cannot estimate more relationships than it is humanly possible given the number of observed variables in our proposed model.    
- To determine the max number number of relationships possibly estimable, we use the following formula $p(p+1)/2$.  

***

- This tells us that, if $p = 3$, then we can estimate at most $3(3+1)/2 = 6$ six parameters. To get our degrees of freedom we simply subtract this from our model parameters ($q = 6$), which means we have 0 degrees of freedom. 
- When $df >= 0$ we have an identified model!   
- If $df < 0$ we have too many parameters and therefore cannot identify a unique solution for our estimated parameters. That is like having more questions than you have answers!    
- Solution? You probably goofed up determining the model parameters (p) and should carefully go through the steps outlined by Raykov and Marcoulides (2006).   




  



